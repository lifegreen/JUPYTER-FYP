{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NinaproDB:\n",
    "    winSize = 256\n",
    "    step = 64\n",
    "    subCount = 0\n",
    "\n",
    "    def __init__(self, gesNum):\n",
    "        self.Data = [ [] for i in range(gesNum) ] \n",
    "        self.gesNum = gesNum\n",
    "        return\n",
    "\n",
    "    def __str__(self):\n",
    "        gesNum = len(self.Data)\n",
    "        \n",
    "        string = \"%d %s \\n\" % (self.subCount, 'subject' if self.subCount==1 else 'subjects')\n",
    "        string += \"%d gestures\\n\" % gesNum\n",
    "\n",
    "        winTotal = 0\n",
    "        for ges, num in zip(self.Data, range(gesNum)):\n",
    "            count = len(ges)\n",
    "            string += \"Gesture %d - %d windows\\n\" % (num, count)\n",
    "            winTotal += count\n",
    "        \n",
    "        string += \"%d windows total\\n\" % winTotal\n",
    "            \n",
    "        return string\n",
    "\n",
    "    def readDataBase(self, folder, subject, exercise):\n",
    "        subjects  = r'\\d+' if subject == 'all' else str(subject).replace(', ', '')\n",
    "        exercises = r'\\d' if exercise == 'all' else str(exercise).replace(', ', '')\n",
    "        match = r'\\AS{}_.*E{}.*\\.mat\\Z'.format(subjects, exercises)\n",
    "\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                if re.search(match, file):\n",
    "                    self.read(os.path.join(root, file))\n",
    "                    self.subCount += 1\n",
    "            \n",
    "    def read(self, file):\n",
    "        print('Reading:', file)\n",
    "        dataset = loadmat(file)\n",
    "        signal = dataset['emg']\n",
    "        labels = np.squeeze(dataset['restimulus']) # By default this returns list of lists, each with a single scalar.\n",
    "                                                   # So np.squeeze is used to turn it into a vector.\n",
    "        signal = self.preprocess(signal)\n",
    "        \n",
    "        for start in range(0, len(signal) - self.winSize, self.step):\n",
    "            end = start + self.winSize\n",
    "            \n",
    "            if labels[start] == labels[end-1]:\n",
    "                self.Data[labels[start]].append(signal[start:end])\n",
    "                \n",
    "    def readMat(self, folder):\n",
    "        for i in range(self.gesNum):\n",
    "            file = 'motion' + str(i) + '.mat'\n",
    "            print('Reading:', file)\n",
    "            motion = loadmat(os.path.join(folder, file))['motion' + str(i)]\n",
    "            motion = motion[~np.all(motion == 0, axis=1)] # remove rows with all zero values\n",
    "            \n",
    "            step = 64\n",
    "            window = 512\n",
    "            \n",
    "            for start in range(0, len(motion) - window, step):\n",
    "                end = start + window\n",
    "                self.Data[i].append(motion[start:end])\n",
    "\n",
    "    def preprocess(self, signal):\n",
    "        # For each channel subtract the mean\n",
    "#         mean = np.mean(signal)\n",
    "        for i in range(signal.shape[1]):\n",
    "            mean = np.mean(signal[:,i])\n",
    "            signal[:,i] -= mean\n",
    "            \n",
    "        return signal\n",
    "\n",
    "    def prepareData(self, ratio):\n",
    "        TrainX = []\n",
    "        TrainY = []\n",
    "        ValidX = []\n",
    "        ValidY = []\n",
    "\n",
    "        for ges, num in zip(self.Data, range(self.gesNum)):\n",
    "            if not num == 0:\n",
    "#                     # Since there are a lot more rest gesture samples,\n",
    "#                     # only use as much as the most data\n",
    "#                     length = max(map(len, self.Data))\n",
    "#                 else:\n",
    "                length = len(ges)\n",
    "#                 length = min(map(len, self.Data))\n",
    "\n",
    "                middle = int(length * ratio)\n",
    "\n",
    "                TrainX.extend(ges[middle:length]) # |middle_____:\n",
    "                ValidX.extend(ges[:middle]) # :____ |middle\n",
    "\n",
    "                TrainY.extend( [num] * (length - middle) )\n",
    "                ValidY.extend( [num] * middle )\n",
    "\n",
    "        return [TrainX, TrainY, ValidX, ValidY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dad783d4c8>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = loadmat(r'C:\\Users\\Mark\\Downloads\\Datbase 1\\S1_A1_E1.mat')\n",
    "signal = dataset['emg']\n",
    "labels = np.squeeze(dataset['stimulus']) \n",
    "Fs = 100\n",
    "X = np.array(range(len(signal))) / Fs\n",
    "%matplotlib qt \n",
    "plt.plot(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.256 * 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S10_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S11_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S12_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S13_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S14_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S15_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S16_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S17_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S18_A1_E1.mat\n",
      "Reading: C:\\Users\\Mark\\Downloads\\Datbase 1\\S19_A1_E1.mat\n",
      "10 subjects \n",
      "13 gestures\n",
      "Gesture 0 - 4374 windows\n",
      "Gesture 1 - 198 windows\n",
      "Gesture 2 - 201 windows\n",
      "Gesture 3 - 224 windows\n",
      "Gesture 4 - 127 windows\n",
      "Gesture 5 - 134 windows\n",
      "Gesture 6 - 164 windows\n",
      "Gesture 7 - 209 windows\n",
      "Gesture 8 - 208 windows\n",
      "Gesture 9 - 160 windows\n",
      "Gesture 10 - 130 windows\n",
      "Gesture 11 - 113 windows\n",
      "Gesture 12 - 152 windows\n",
      "6394 windows total\n",
      "\n",
      "[1864, 1864, 156, 156]\n",
      "<class 'numpy.ndarray'>\n",
      "(256, 10, 1)\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n"
     ]
    }
   ],
   "source": [
    "## IMPORT DATA ##\n",
    "\n",
    "DB = NinaproDB(13)\n",
    "DB.readDataBase(r'C:\\Users\\Mark\\Downloads\\Datbase 1', '1\\d', '1')\n",
    "\n",
    "print(DB)\n",
    "# signal = []\n",
    "# for win in DB.Data[1]:\n",
    "#     signal.extend(list(win[:,3]))\n",
    "    \n",
    "# plt.plot(signal)\n",
    "\n",
    "[TrainX, TrainY, ValidX, ValidY] = DB.prepareData(0.08)\n",
    "print(list(map(len, [TrainX, TrainY, ValidX, ValidY])))\n",
    "\n",
    "# results, clf = gumpy.classify('SVM', X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# Add a colour channel dimension for conv net input\n",
    "TrainX = [np.expand_dims(x, axis=2) for x in TrainX]\n",
    "TrainX = np.stack(TrainX, axis=0 )\n",
    "\n",
    "ValidX = [np.expand_dims(x, axis=2) for x in ValidX]\n",
    "ValidX = np.stack(ValidX, axis=0 )\n",
    "\n",
    "\n",
    "c = list(zip(TrainX, TrainY))\n",
    "np.random.shuffle(c)\n",
    "TrainX, TrainY = zip(*c)\n",
    "TrainX = np.array(TrainX)\n",
    "TrainY = np.array(TrainY)\n",
    "\n",
    "print(type(TrainX))\n",
    "print(TrainX[0].shape)\n",
    "print(set(ValidY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least the script starts...\n",
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "<keras.engine.sequential.Sequential object at 0x000001F7BD6A96C8>\n",
      "Train on 1864 samples, validate on 156 samples\n",
      "Epoch 1/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 3.7148 - accuracy: 0.1813 - val_loss: 2.4613 - val_accuracy: 0.1282\n",
      "Epoch 2/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 1.9043 - accuracy: 0.3444 - val_loss: 2.4086 - val_accuracy: 0.1346\n",
      "Epoch 3/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 1.6040 - accuracy: 0.4340 - val_loss: 2.4239 - val_accuracy: 0.1667\n",
      "Epoch 4/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 1.4034 - accuracy: 0.5054 - val_loss: 2.5352 - val_accuracy: 0.1795\n",
      "Epoch 5/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 1.2590 - accuracy: 0.5697 - val_loss: 2.5975 - val_accuracy: 0.1538\n",
      "Epoch 6/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 1.0727 - accuracy: 0.6330 - val_loss: 2.5034 - val_accuracy: 0.1795\n",
      "Epoch 7/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 1.0281 - accuracy: 0.6550 - val_loss: 2.6430 - val_accuracy: 0.1474\n",
      "Epoch 8/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.8880 - accuracy: 0.6883 - val_loss: 2.7431 - val_accuracy: 0.0962\n",
      "Epoch 9/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.7387 - accuracy: 0.7462 - val_loss: 3.2298 - val_accuracy: 0.0833\n",
      "Epoch 10/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.6835 - accuracy: 0.7597 - val_loss: 2.8913 - val_accuracy: 0.1474\n",
      "Epoch 11/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.6459 - accuracy: 0.7827 - val_loss: 2.8885 - val_accuracy: 0.1923\n",
      "Epoch 12/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.5938 - accuracy: 0.7929 - val_loss: 3.0831 - val_accuracy: 0.1410\n",
      "Epoch 13/30\n",
      "1864/1864 [==============================] - 21s 11ms/step - loss: 0.5259 - accuracy: 0.8133 - val_loss: 3.1630 - val_accuracy: 0.2244\n",
      "Epoch 14/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.4575 - accuracy: 0.8412 - val_loss: 2.7774 - val_accuracy: 0.3269\n",
      "Epoch 15/30\n",
      "1864/1864 [==============================] - 18s 9ms/step - loss: 0.4176 - accuracy: 0.8557 - val_loss: 2.6519 - val_accuracy: 0.3269\n",
      "Epoch 16/30\n",
      "1864/1864 [==============================] - 19s 10ms/step - loss: 0.4342 - accuracy: 0.8482 - val_loss: 2.5886 - val_accuracy: 0.3077\n",
      "Epoch 17/30\n",
      "1864/1864 [==============================] - 21s 11ms/step - loss: 0.3296 - accuracy: 0.8895 - val_loss: 2.2535 - val_accuracy: 0.3718\n",
      "Epoch 18/30\n",
      "1864/1864 [==============================] - 20s 10ms/step - loss: 0.3887 - accuracy: 0.8621 - val_loss: 2.0739 - val_accuracy: 0.3718\n",
      "Epoch 19/30\n",
      "1864/1864 [==============================] - 20s 11ms/step - loss: 0.3346 - accuracy: 0.8857 - val_loss: 1.8359 - val_accuracy: 0.4615\n",
      "Epoch 20/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.3087 - accuracy: 0.8895 - val_loss: 2.3124 - val_accuracy: 0.3846\n",
      "Epoch 21/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.2996 - accuracy: 0.8986 - val_loss: 1.7627 - val_accuracy: 0.4808\n",
      "Epoch 22/30\n",
      "1864/1864 [==============================] - 18s 9ms/step - loss: 0.2112 - accuracy: 0.9303 - val_loss: 1.8143 - val_accuracy: 0.4551\n",
      "Epoch 23/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.2004 - accuracy: 0.9345 - val_loss: 1.7662 - val_accuracy: 0.4808\n",
      "Epoch 24/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.2556 - accuracy: 0.9093 - val_loss: 1.7713 - val_accuracy: 0.5192\n",
      "Epoch 25/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.1835 - accuracy: 0.9372 - val_loss: 1.6197 - val_accuracy: 0.4872\n",
      "Epoch 26/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.1765 - accuracy: 0.9426 - val_loss: 1.9860 - val_accuracy: 0.4423\n",
      "Epoch 27/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.1693 - accuracy: 0.9453 - val_loss: 1.7969 - val_accuracy: 0.5449\n",
      "Epoch 28/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.1536 - accuracy: 0.9447 - val_loss: 1.7462 - val_accuracy: 0.5705\n",
      "Epoch 29/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.1419 - accuracy: 0.9490 - val_loss: 1.6223 - val_accuracy: 0.5897\n",
      "Epoch 30/30\n",
      "1864/1864 [==============================] - 18s 10ms/step - loss: 0.2360 - accuracy: 0.9201 - val_loss: 1.5440 - val_accuracy: 0.5449\n",
      "Predictions:\t [1 1 1 1 1 1 1 1 1 1 1 9 1 1 1 2 2 3 3 3]\n",
      "Answers:\t\t [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n",
      "Unique (pred):\t\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12}\n",
      "Unique (correct):\t {1, 2, 3, 4, 5, 7, 8, 9, 10, 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"At least the script starts...\")\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "## CREATE NETWORK ##\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "num_classes = 13\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(5, 5), strides=1,\n",
    "#                  activation='relu',\n",
    "#                  input_shape=(512,8,1), data_format=\"channels_last\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## PAPER 2 ##\n",
    "# model.add(Conv2D(32, kernel_size=(1,10), activation='relu', input_shape=(512,8,1), padding='same'))\n",
    "# model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "# # model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "# model.add(Conv2D(64, kernel_size=5, activation='relu', padding='same'))\n",
    "# # model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "# model.add(Conv2D(64, kernel_size=(5,1), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(64, kernel_size=1, activation='relu', padding='same'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## PAPER 3 ##\n",
    "model.add(Conv2D(32, kernel_size=5, activation='relu', input_shape=(256, 10, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(Dropout(.8))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(model)\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## TRAIN THE MODEL.##\n",
    "model.fit(\n",
    "    TrainX,\n",
    "    to_categorical(TrainY),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_data=(ValidX, to_categorical(ValidY)),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save/Load weights\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"Trained Wieghts/%d_%m_%Y_%H_%M\")\n",
    "model.save_weights('%s.h5' % dt_string)\n",
    "\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = np.argmax(model.predict(ValidX), axis=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print('Predictions:\\t', predictions[:20]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print('Answers:\\t\\t', ValidY[:20]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "correct = predictions[ValidY==predictions]\n",
    "\n",
    "print('Unique (pred):\\t\\t', set(predictions))\n",
    "print('Unique (correct):\\t', set(correct))\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.hist(predictions, bins=11)  # arguments are passed to np.histogram\n",
    "# print(np.histogram(predictions, bins=11))\n",
    "# plt.title('Predictions')\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.hist(correct, bins=11)  # arguments are passed to np.histogram\n",
    "# plt.title('Correct')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "57*0.15 + 67*0.1 + 53*.75\n",
    "np.mean([83, 52, 53, 72, 72])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
