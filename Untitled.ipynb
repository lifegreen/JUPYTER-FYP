{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least the script starts...\n"
     ]
    }
   ],
   "source": [
    "print(\"At least the script starts...\")\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isListEmpty(inList):\n",
    "# Checks if a list consists only of Empty nested lists\n",
    "        if isinstance(inList, list): # if list (returns false if empty)\n",
    "            return all(map(isListEmpty, inList))\n",
    "        return False # Not a list\n",
    "\n",
    "class NinaproDB:\n",
    "    winSize = 25\n",
    "    overlap = 12\n",
    "\n",
    "    def __init__(self):\n",
    "        ## PLZ PLZ PLZ FIX ##\n",
    "        # Created nested lists to store database\n",
    "        #                               gestures             reps                 subjects            exercises\n",
    "        self.Data = [ [ [ [ [] for i in range(13) ] for i in range(11) ] for i in range(64)] for i in range(3)]\n",
    "        return\n",
    "\n",
    "    def __str__(self):\n",
    "        gesCount = [0 for i in range(13)]\n",
    "        subCount = 0\n",
    "        \n",
    "        for exe in self.Data:\n",
    "            if not isListEmpty(exe):\n",
    "                for sub in exe:\n",
    "                    if not isListEmpty(sub):\n",
    "                        subCount += 1\n",
    "                        for rep in sub:\n",
    "                            for ges, num in zip(rep, range(len(rep))):\n",
    "                                gesCount[num] += len(ges)\n",
    "\n",
    "        string = \"%d %s \\n\" % (subCount, 'subject' if subCount==1 else 'subjects')\n",
    "        string += \"%d windows total\\n\" % sum(gesCount)\n",
    "        for ges in gesCount:\n",
    "            string += \"Gesture %d - %d windows\\n\" % (gesCount.index(ges), ges)\n",
    "        return string\n",
    "\n",
    "    def readDataBase(self, folder, subject, exercise):\n",
    "        subjects  = r'\\d+' if subject == 'all' else str(subject).replace(', ', '')\n",
    "        exercises = r'\\d' if exercise == 'all' else str(exercise).replace(', ', '')\n",
    "        match = r'\\AS{}_.*E{}.*\\.mat\\Z'.format(subjects, exercises)\n",
    "\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                if re.search(match, file):\n",
    "                     self.read(os.path.join(root, file))\n",
    "\n",
    "    def read(self, file):\n",
    "        print('Reading: %s', file)\n",
    "        dataset = loadmat(file)\n",
    "        signal = dataset['emg']\n",
    "        labels = dataset['restimulus']\n",
    "        exe    = dataset['exercise'].item() - 1\n",
    "        sub    = dataset['subject'].item() - 1\n",
    "        rep    = dataset['rerepetition']\n",
    "\n",
    "        # Divide signal into time windows\n",
    "        # length = (len(signal) // winSize) * winSize\n",
    "\n",
    "        step = self.winSize - self.overlap\n",
    "        # self.windows = [signal[i : i + self.winSize] for i in range(0, len(signal), step)]\n",
    "        # if (self.windows[-1].shape != self.windows[1].shape) :\n",
    "        #     del self.windows[-1]\n",
    "\n",
    "        for start in range(0, len(signal) - self.winSize, step):\n",
    "            end = start + self.winSize\n",
    "            if labels[start] == labels[end-1]:\n",
    "#PLS FIX#\n",
    "                self.Data[exe][sub][rep[start].item() - 1][labels[start].item()].append(signal[start:end])\n",
    "# [0] are to turn a for some reason nested list into a scalar\n",
    "# -1  is for converting to 0 indexing\n",
    "\n",
    "            # print(start)\n",
    "            # print(end)\n",
    "            # print(exe[0][0])\n",
    "            # print(sub[0][0])\n",
    "            # print(rep[start][0])\n",
    "            # print(labels[start][0])\n",
    "            # print()\n",
    "\n",
    "\n",
    "    def prepareData(self, ratio):\n",
    "        TrainX = []\n",
    "        TrainY = []\n",
    "        ValidX = []\n",
    "        ValidY = []\n",
    "        gestures = [ [] for i in range(13) ] \n",
    "\n",
    "        for exe in self.Data:\n",
    "            if not isListEmpty(exe):\n",
    "                for sub in exe:\n",
    "                    if not isListEmpty(sub):\n",
    "                        for rep in sub:\n",
    "                            for ges, num in zip(rep, range(len(rep))):\n",
    "                                gestures[num].extend(ges)              \n",
    "                                \n",
    "        for ges, num in zip(gestures, range(len(gestures))):                        \n",
    "            if not num == 0:\n",
    "                length = len(ges)\n",
    "\n",
    "                middle = int(length * ratio)\n",
    "\n",
    "                TrainX.extend(ges[middle:]) # |middle_____:\n",
    "                ValidX.extend(ges[:middle]) # :____ |middle\n",
    "\n",
    "                TrainY.extend( [num] * (length - middle) )\n",
    "                ValidY.extend( [num] * middle )\n",
    "\n",
    "        return [TrainX, TrainY , ValidX, ValidY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S10_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S11_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S12_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S13_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S14_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S15_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S16_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S17_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S18_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S19_A1_E1.mat\n",
      "10 subjects \n",
      "73341 windows total\n",
      "Gesture 0 - 42618 windows\n",
      "Gesture 1 - 2753 windows\n",
      "Gesture 2 - 2719 windows\n",
      "Gesture 3 - 2835 windows\n",
      "Gesture 4 - 2350 windows\n",
      "Gesture 5 - 2393 windows\n",
      "Gesture 6 - 2595 windows\n",
      "Gesture 1 - 2753 windows\n",
      "Gesture 8 - 2783 windows\n",
      "Gesture 9 - 2502 windows\n",
      "Gesture 10 - 2263 windows\n",
      "Gesture 10 - 2263 windows\n",
      "Gesture 12 - 2514 windows\n",
      "\n",
      "[21514, 21514, 9209, 9209]\n",
      "(25, 10)\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n"
     ]
    }
   ],
   "source": [
    "## IMPORT DATA ##\n",
    "\n",
    "\n",
    "DB = NinaproDB()\n",
    "DB.readDataBase(r'C:\\Users\\Mark\\Downloads\\Datbase 1', '1\\d', '1')\n",
    "\n",
    "print(DB)\n",
    "\n",
    "[TrainX, TrainY , ValidX, ValidY] = DB.prepareData(0.3)\n",
    "print(list(map(len, [TrainX, TrainY , ValidX, ValidY])))\n",
    "\n",
    "# results, clf = gumpy.classify('SVM', X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# TrainX = [np.expand_dims(x, axis=2) for x in TrainX]\n",
    "# TrainX = np.stack(TrainX, axis=0 )\n",
    "\n",
    "# ValidX = [np.expand_dims(x, axis=2) for x in ValidX]\n",
    "# ValidX = np.stack(ValidX, axis=0 )\n",
    "\n",
    "print(TrainX[0].shape)\n",
    "print(set(ValidY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22036 - 21514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21514, 50)\n",
      "(9209, 50)\n"
     ]
    }
   ],
   "source": [
    "def extractFeatures(windows):\n",
    "    windows = np.squeeze(windows)\n",
    "    N, L, C = windows.shape # Total number of: windows, time samples, channels\n",
    "    \n",
    "    bins = 9\n",
    "    hist = np.zeros((N,C*bins))\n",
    "    \n",
    "    mav = np.zeros((N,C))\n",
    "    rms = np.zeros((N,C))\n",
    "    std = np.zeros((N,C))\n",
    "    zc  = np.zeros((N,C))\n",
    "    wl  = np.zeros((N,C))\n",
    "    ssc = np.zeros((N,C))\n",
    "    \n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            channel = windows[n,:,c]\n",
    "            \n",
    "#             hist[n,c*bins:c*bins+bins] = np.histogram(channel, bins=bins)[0]\n",
    "            \n",
    "            mav[n,c] = np.mean(np.abs(channel))\n",
    "#             rms[n,c] = np.sqrt(np.mean(np.square(a)))\n",
    "            std[n,c] = np.std(channel)\n",
    "            zc[n,c]  = (np.diff(np.sign(channel)) != 0).sum()\n",
    "            \n",
    "            diffs = np.diff(channel)\n",
    "            wl[n,c]  = np.abs(diffs).sum()\n",
    "            ssc[n,c] = (np.diff(np.sign(diffs)) != 0).sum()\n",
    "    \n",
    "    return np.hstack((mav, std, zc, wl, ssc))\n",
    "            \n",
    "TrainF = extractFeatures(TrainX)\n",
    "ValidF = extractFeatures(ValidX)\n",
    "\n",
    "print(TrainF.shape)\n",
    "print(ValidF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73328000e-01, 1.21576000e-01, 8.12592000e-01, 4.89240000e-02,\n",
       "       4.85200000e-03, 2.50000000e-03, 5.96720000e-02, 5.60444000e-01,\n",
       "       1.65432000e-01, 2.48240000e-01, 1.51074954e-02, 1.42720785e-02,\n",
       "       8.27110194e-02, 2.07135565e-02, 4.74662996e-03, 4.89897949e-04,\n",
       "       1.65767915e-02, 5.74390604e-02, 2.44070108e-02, 1.28496537e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.73200000e-01, 2.17300000e-01,\n",
       "       1.09850000e+00, 1.41400000e-01, 2.95000000e-02, 5.00000000e-03,\n",
       "       1.58700000e-01, 6.93200000e-01, 2.51600000e-01, 1.21800000e-01,\n",
       "       1.10000000e+01, 1.00000000e+01, 1.00000000e+01, 6.00000000e+00,\n",
       "       6.00000000e+00, 2.00000000e+00, 6.00000000e+00, 5.00000000e+00,\n",
       "       1.10000000e+01, 1.30000000e+01])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.498642632207622 %  accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:691: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = LinearDiscriminantAnalysis()\n",
    "clf = QuadraticDiscriminantAnalysis()\n",
    "# clf = SVC()\n",
    "# clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(TrainF, TrainY)\n",
    "\n",
    "predictions = clf.predict(ValidF)\n",
    "\n",
    "correct = predictions == ValidY\n",
    "accuracy = np.count_nonzero(correct) / len(correct)\n",
    "print(accuracy * 100, '%  accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x0000021B49B4D888>\n"
     ]
    }
   ],
   "source": [
    "## CREATE NETWORK ##\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "num_classes = 13\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(5, 5), strides=1,\n",
    "#                  activation='relu',\n",
    "#                  input_shape=(25, 10, 1), data_format=\"channels_last\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## PAPER 2 ##\n",
    "# model.add(Conv2D(32, kernel_size=(1,10), activation='relu', input_shape=(25,10,1), padding='same'))\n",
    "# model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "# # model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "# model.add(Conv2D(64, kernel_size=5, activation='relu', padding='same'))\n",
    "# # model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "# model.add(Conv2D(64, kernel_size=(5,1), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(64, kernel_size=1, activation='relu', padding='same'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## PAPER 3 ##\n",
    "model.add(Conv2D(32, kernel_size=5, activation='relu', input_shape=(25,10,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(25,10,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(model)\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11712 samples, validate on 4252 samples\n",
      "Epoch 1/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.7000 - accuracy: 0.7644 - val_loss: 1.4629 - val_accuracy: 0.5786\n",
      "Epoch 2/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.6652 - accuracy: 0.7746 - val_loss: 1.4623 - val_accuracy: 0.5807\n",
      "Epoch 3/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.6277 - accuracy: 0.7891 - val_loss: 1.4451 - val_accuracy: 0.5929\n",
      "Epoch 4/30\n",
      "11712/11712 [==============================] - 14s 1ms/step - loss: 0.5976 - accuracy: 0.7964 - val_loss: 1.3897 - val_accuracy: 0.6018\n",
      "Epoch 5/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.5633 - accuracy: 0.8051 - val_loss: 1.3870 - val_accuracy: 0.6072\n",
      "Epoch 6/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.5280 - accuracy: 0.8175 - val_loss: 1.4913 - val_accuracy: 0.6108\n",
      "Epoch 7/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.5119 - accuracy: 0.8290 - val_loss: 1.5175 - val_accuracy: 0.6079\n",
      "Epoch 8/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.4864 - accuracy: 0.8337 - val_loss: 1.5668 - val_accuracy: 0.5985\n",
      "Epoch 9/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.4617 - accuracy: 0.8434 - val_loss: 1.4527 - val_accuracy: 0.6214\n",
      "Epoch 10/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.4455 - accuracy: 0.8462 - val_loss: 1.5599 - val_accuracy: 0.6197\n",
      "Epoch 11/30\n",
      "11712/11712 [==============================] - 14s 1ms/step - loss: 0.4215 - accuracy: 0.8541 - val_loss: 1.5675 - val_accuracy: 0.6049\n",
      "Epoch 12/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.4070 - accuracy: 0.8571 - val_loss: 1.5954 - val_accuracy: 0.6164\n",
      "Epoch 13/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3966 - accuracy: 0.8611 - val_loss: 1.5863 - val_accuracy: 0.6202\n",
      "Epoch 14/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3708 - accuracy: 0.8685 - val_loss: 1.6331 - val_accuracy: 0.6105\n",
      "Epoch 15/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3632 - accuracy: 0.8735 - val_loss: 1.6409 - val_accuracy: 0.6075\n",
      "Epoch 16/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3560 - accuracy: 0.8746 - val_loss: 1.7564 - val_accuracy: 0.6065\n",
      "Epoch 17/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3251 - accuracy: 0.8864 - val_loss: 1.7605 - val_accuracy: 0.6089\n",
      "Epoch 18/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3266 - accuracy: 0.8853 - val_loss: 1.7095 - val_accuracy: 0.6152\n",
      "Epoch 19/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3186 - accuracy: 0.8883 - val_loss: 1.7582 - val_accuracy: 0.6079\n",
      "Epoch 20/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3214 - accuracy: 0.8876 - val_loss: 1.8328 - val_accuracy: 0.6171\n",
      "Epoch 21/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.3086 - accuracy: 0.8883 - val_loss: 1.7124 - val_accuracy: 0.6209\n",
      "Epoch 22/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2725 - accuracy: 0.9029 - val_loss: 1.8582 - val_accuracy: 0.6112\n",
      "Epoch 23/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2701 - accuracy: 0.9057 - val_loss: 1.7802 - val_accuracy: 0.6199\n",
      "Epoch 24/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2610 - accuracy: 0.9080 - val_loss: 1.8870 - val_accuracy: 0.6131\n",
      "Epoch 25/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2743 - accuracy: 0.9036 - val_loss: 1.8688 - val_accuracy: 0.6112\n",
      "Epoch 26/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2434 - accuracy: 0.9127 - val_loss: 1.8855 - val_accuracy: 0.6225\n",
      "Epoch 27/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2390 - accuracy: 0.9149 - val_loss: 1.9535 - val_accuracy: 0.6228\n",
      "Epoch 28/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2421 - accuracy: 0.9167 - val_loss: 1.8913 - val_accuracy: 0.6331\n",
      "Epoch 29/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.2457 - accuracy: 0.9140 - val_loss: 1.9547 - val_accuracy: 0.6206\n",
      "Epoch 30/30\n",
      "11712/11712 [==============================] - 15s 1ms/step - loss: 0.1991 - accuracy: 0.9315 - val_loss: 1.9710 - val_accuracy: 0.6268\n",
      "Predictions:\t [ 2  1  8 12 12  2  2  3  4  3  3  3  3  3  7  4  5  5  5  8]\n",
      "Answers:\t\t [1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6]\n",
      "Unique (pred):\t\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique (correct):\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n"
     ]
    }
   ],
   "source": [
    "## TRAIN THE MODEL.##\n",
    "model.fit(\n",
    "    TrainX,\n",
    "    to_categorical(TrainY),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_data=(ValidX, to_categorical(ValidY)),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save/Load weights\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"Trained Wieghts/%d_%m_%Y_%H_%M\")\n",
    "model.save_weights('%s.h5' % dt_string)\n",
    "\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = np.argmax(model.predict(ValidX), axis=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print('Predictions:\\t', predictions[:20]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print('Answers:\\t\\t', ValidY[:20]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "correct = predictions[ValidY==predictions]\n",
    "\n",
    "print('Unique (pred):\\t\\t', set(predictions))\n",
    "print('Unique (correct):\\t', set(correct))\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.hist(predictions, bins=11)  # arguments are passed to np.histogram\n",
    "# print(np.histogram(predictions, bins=11))\n",
    "# plt.title('Predictions')\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.hist(correct, bins=11)  # arguments are passed to np.histogram\n",
    "# plt.title('Correct')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least the script starts...\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S10_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S11_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S12_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S13_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S14_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S15_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S16_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S17_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S18_A1_E1.mat\n",
      "Reading: %s C:\\Users\\Mark\\Downloads\\Datbase 1\\S19_A1_E1.mat\n",
      "10 subjects \n",
      "6394 windows total\n",
      "Gesture 0 - 4374 windows\n",
      "Gesture 1 - 198 windows\n",
      "Gesture 2 - 201 windows\n",
      "Gesture 3 - 224 windows\n",
      "Gesture 4 - 127 windows\n",
      "Gesture 5 - 134 windows\n",
      "Gesture 6 - 164 windows\n",
      "Gesture 7 - 209 windows\n",
      "Gesture 8 - 208 windows\n",
      "Gesture 9 - 160 windows\n",
      "Gesture 10 - 130 windows\n",
      "Gesture 11 - 113 windows\n",
      "Gesture 12 - 152 windows\n",
      "\n",
      "[1859, 1859, 161, 161]\n",
      "(256, 10, 1)\n",
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "<keras.engine.sequential.Sequential object at 0x0000021B53AEC408>\n",
      "Train on 1859 samples, validate on 161 samples\n",
      "Epoch 1/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 2.3745 - accuracy: 0.2829 - val_loss: 2.3655 - val_accuracy: 0.2547\n",
      "Epoch 2/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 1.2940 - accuracy: 0.5654 - val_loss: 2.2186 - val_accuracy: 0.2981\n",
      "Epoch 3/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 1.0534 - accuracy: 0.6509 - val_loss: 2.4414 - val_accuracy: 0.1677\n",
      "Epoch 4/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.8679 - accuracy: 0.7095 - val_loss: 3.0492 - val_accuracy: 0.1925\n",
      "Epoch 5/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.5885 - accuracy: 0.8037 - val_loss: 4.1145 - val_accuracy: 0.1118\n",
      "Epoch 6/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.4059 - accuracy: 0.8774 - val_loss: 4.8324 - val_accuracy: 0.1118\n",
      "Epoch 7/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.5692 - accuracy: 0.8187 - val_loss: 4.1914 - val_accuracy: 0.1304\n",
      "Epoch 8/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.2402 - accuracy: 0.9301 - val_loss: 3.6637 - val_accuracy: 0.1491\n",
      "Epoch 9/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.2248 - accuracy: 0.9322 - val_loss: 4.3648 - val_accuracy: 0.1615\n",
      "Epoch 10/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.1425 - accuracy: 0.9580 - val_loss: 3.9675 - val_accuracy: 0.2547\n",
      "Epoch 11/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.1740 - accuracy: 0.9532 - val_loss: 3.7529 - val_accuracy: 0.2857\n",
      "Epoch 12/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.1310 - accuracy: 0.9650 - val_loss: 3.2659 - val_accuracy: 0.2981\n",
      "Epoch 13/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.1063 - accuracy: 0.9726 - val_loss: 3.2090 - val_accuracy: 0.4410\n",
      "Epoch 14/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.4238 - accuracy: 0.8677 - val_loss: 1.6606 - val_accuracy: 0.5901\n",
      "Epoch 15/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.1687 - accuracy: 0.9462 - val_loss: 1.7098 - val_accuracy: 0.5901\n",
      "Epoch 16/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.7501 - accuracy: 0.8080 - val_loss: 1.1852 - val_accuracy: 0.6398\n",
      "Epoch 17/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.1819 - accuracy: 0.9419 - val_loss: 0.8634 - val_accuracy: 0.7516\n",
      "Epoch 18/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.0864 - accuracy: 0.9796 - val_loss: 0.7308 - val_accuracy: 0.7578\n",
      "Epoch 19/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.1301 - accuracy: 0.9677 - val_loss: 0.9184 - val_accuracy: 0.7453\n",
      "Epoch 20/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.5115 - accuracy: 0.8698 - val_loss: 0.7117 - val_accuracy: 0.7702\n",
      "Epoch 21/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.1152 - accuracy: 0.9677 - val_loss: 0.6627 - val_accuracy: 0.8199\n",
      "Epoch 22/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.2868 - accuracy: 0.9473 - val_loss: 0.7959 - val_accuracy: 0.8509\n",
      "Epoch 23/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.1429 - accuracy: 0.9570 - val_loss: 0.5292 - val_accuracy: 0.8447\n",
      "Epoch 24/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.0554 - accuracy: 0.9855 - val_loss: 0.7381 - val_accuracy: 0.8075\n",
      "Epoch 25/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.4168 - accuracy: 0.9155 - val_loss: 0.5746 - val_accuracy: 0.8447\n",
      "Epoch 26/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.0932 - accuracy: 0.9726 - val_loss: 0.5772 - val_accuracy: 0.8634\n",
      "Epoch 27/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.0342 - accuracy: 0.9925 - val_loss: 0.3377 - val_accuracy: 0.9006\n",
      "Epoch 28/30\n",
      "1859/1859 [==============================] - 16s 9ms/step - loss: 0.0192 - accuracy: 0.9989 - val_loss: 0.4004 - val_accuracy: 0.8820\n",
      "Epoch 29/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.3663 - accuracy: 0.9118 - val_loss: 0.6597 - val_accuracy: 0.8137\n",
      "Epoch 30/30\n",
      "1859/1859 [==============================] - 17s 9ms/step - loss: 0.0992 - accuracy: 0.9645 - val_loss: 0.4306 - val_accuracy: 0.8634\n",
      "Predictions:\t [ 1  3  7 10  3  1  2  8  1  9  3  3  1 10  9 10  3 12  1  1]\n",
      "Answers:\t\t [1, 3, 7, 10, 12, 1, 2, 8, 1, 11, 3, 3, 1, 10, 9, 10, 2, 12, 1, 2]\n",
      "Unique (pred):\t\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique (correct):\t {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"At least the script starts...\")\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Flatten, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def isListEmpty(inList):\n",
    "# Checks if a list consists only of Empty nested lists\n",
    "        if isinstance(inList, list): # if list (returns false if empty)\n",
    "            return all(map(isListEmpty, inList))\n",
    "        return False # Not a list\n",
    "\n",
    "class NinaproDB:\n",
    "    winSize = 256\n",
    "    step = 64\n",
    "\n",
    "    def __init__(self):\n",
    "        ## PLZ PLZ PLZ FIX ##\n",
    "        # Created nested lists to store database\n",
    "        #                               gestures             reps                 subjects            exercises\n",
    "        self.Data = [ [ [ [ [] for i in range(13) ] for i in range(11) ] for i in range(64)] for i in range(3)]\n",
    "        return\n",
    "\n",
    "    def __str__(self):\n",
    "        gesCount = [0 for i in range(13)]\n",
    "        subCount = 0\n",
    "\n",
    "        for exe in self.Data:\n",
    "            for sub in exe:\n",
    "                if not isListEmpty(sub):\n",
    "                    subCount += 1\n",
    "                    for rep in sub:\n",
    "                        for ges, num in zip(rep, range(len(rep))):\n",
    "                            gesCount[num] += len(ges)\n",
    "\n",
    "        string = \"%d %s \\n\" % (subCount, 'subject' if subCount==1 else 'subjects')\n",
    "        string += \"%d windows total\\n\" % sum(gesCount)\n",
    "        for ges in gesCount:\n",
    "            string += \"Gesture %d - %d windows\\n\" % (gesCount.index(ges), ges)\n",
    "        return string\n",
    "\n",
    "    def readDataBase(self, folder, subject, exercise):\n",
    "        subjects  = r'\\d+' if subject == 'all' else str(subject).replace(', ', '')\n",
    "        exercises = r'\\d' if exercise == 'all' else str(exercise).replace(', ', '')\n",
    "        match = r'\\AS{}_.*E{}.*\\.mat\\Z'.format(subjects, exercises)\n",
    "\n",
    "        for root, dirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                if re.search(match, file):\n",
    "                     self.read(os.path.join(root, file))\n",
    "\n",
    "    def read(self, file):\n",
    "        print('Reading: %s', file)\n",
    "        dataset = loadmat(file)\n",
    "        signal = dataset['emg']\n",
    "        labels = dataset['restimulus']\n",
    "        exe    = dataset['exercise'].item() - 1\n",
    "        sub    = dataset['subject'].item() - 1\n",
    "        rep    = dataset['rerepetition']\n",
    "\n",
    "        signal = self.preprocess(signal)\n",
    "\n",
    "        # Divide signal into time windows\n",
    "        # length = (len(signal) // winSize) * winSize\n",
    "        # self.windows = [signal[i : i + self.winSize] for i in range(0, len(signal), step)]\n",
    "        # if (self.windows[-1].shape != self.windows[1].shape) :\n",
    "        #     del self.windows[-1]\n",
    "\n",
    "        for start in range(0, len(signal) - self.winSize, self.step):\n",
    "            end = start + self.winSize\n",
    "            if labels[start] == labels[end-1]:\n",
    "#PLS FIX#\n",
    "                self.Data[exe][sub][rep[start].item() - 1][labels[start].item()].append(signal[start:end])\n",
    "# [0] are to turn a for some reason nested list into a scalar\n",
    "# -1  is for converting to 0 indexing\n",
    "\n",
    "            # print(start)\n",
    "            # print(end)\n",
    "            # print(exe[0][0])\n",
    "            # print(sub[0][0])\n",
    "            # print(rep[start][0])\n",
    "            # print(labels[start][0])\n",
    "            # print()\n",
    "\n",
    "    def preprocess(self, signal):\n",
    "        # For each channel subtract the mean\n",
    "        mean = np.mean(signal)\n",
    "        for i in range(signal.shape[1]):\n",
    "#             mean = np.mean(signal[:,i])\n",
    "            signal[:,i] -= mean\n",
    "\n",
    "        return signal\n",
    "\n",
    "\n",
    "    def prepareData(self, ratio):\n",
    "        TrainX = []\n",
    "        TrainY = []\n",
    "        ValidX = []\n",
    "        ValidY = []\n",
    "        # Data = self.Data[:][:][:][1][:]\n",
    "        count = 0\n",
    "        for exe in self.Data:\n",
    "            if not isListEmpty(exe):\n",
    "                for sub in exe:\n",
    "                    if not isListEmpty(sub):\n",
    "                        for rep in sub:\n",
    "                            for ges, num in zip(rep, range(len(rep))):\n",
    "                                if not num == 0:\n",
    "                                    length = len(ges)\n",
    "\n",
    "                                    middle = int(length * ratio)\n",
    "\n",
    "                                    TrainX.extend(ges[middle:]) # |middle_____:\n",
    "                                    ValidX.extend(ges[:middle]) # :____ |middle\n",
    "                                    TrainY.extend( [num] * (length - middle) )\n",
    "                                    ValidY.extend( [num] * middle )\n",
    "\n",
    "        return [TrainX, TrainY , ValidX, ValidY]\n",
    "\n",
    "## IMPORT DATA ##\n",
    "\n",
    "\n",
    "DB = NinaproDB()\n",
    "DB.readDataBase(r'C:\\Users\\Mark\\Downloads\\Datbase 1', '1\\d', '1')\n",
    "\n",
    "print(DB)\n",
    "\n",
    "[TrainX, TrainY , ValidX, ValidY] = DB.prepareData(0.3)\n",
    "print(list(map(len, [TrainX, TrainY , ValidX, ValidY])))\n",
    "\n",
    "# results, clf = gumpy.classify('SVM', X_train, Y_train, X_test, Y_test)\n",
    "\n",
    "# print(results)\n",
    "\n",
    "TrainX = [np.expand_dims(x, axis=2) for x in TrainX]\n",
    "TrainX = np.stack(TrainX, axis=0 )\n",
    "\n",
    "ValidX = [np.expand_dims(x, axis=2) for x in ValidX]\n",
    "ValidX = np.stack(ValidX, axis=0 )\n",
    "\n",
    "print(TrainX[0].shape)\n",
    "print(set(ValidY))\n",
    "\n",
    "\n",
    "## CREATE NETWORK ##\n",
    "num_filters = 8\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "num_classes = 13\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Conv2D(32, kernel_size=(5, 5), strides=1,\n",
    "#                  activation='relu',\n",
    "#                  input_shape=(25, 10, 1), data_format=\"channels_last\"))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## PAPER 2 ##\n",
    "# model.add(Conv2D(32, kernel_size=(1,10), activation='relu', input_shape=(25,10,1), padding='same'))\n",
    "# model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "# # model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "# model.add(Conv2D(64, kernel_size=5, activation='relu', padding='same'))\n",
    "# # model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "# model.add(Conv2D(64, kernel_size=(5,1), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(64, kernel_size=1, activation='relu', padding='same'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "## PAPER 3 ##\n",
    "model.add(Conv2D(32, kernel_size=5, activation='relu', input_shape=(256,10,1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(model)\n",
    "\n",
    "#compile model using accuracy to measure model performance\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "## TRAIN THE MODEL.##\n",
    "model.fit(\n",
    "    TrainX,\n",
    "    to_categorical(TrainY),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    validation_data=(ValidX, to_categorical(ValidY)),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save/Load weights\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"Trained Wieghts/%d_%m_%Y_%H_%M\")\n",
    "model.save_weights('%s.h5' % dt_string)\n",
    "\n",
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = np.argmax(model.predict(ValidX), axis=1)\n",
    "\n",
    "# Print our model's predictions.\n",
    "print('Predictions:\\t', predictions[:20]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print('Answers:\\t\\t', ValidY[:20]) # [7, 2, 1, 0, 4]\n",
    "\n",
    "correct = predictions[ValidY==predictions]\n",
    "\n",
    "print('Unique (pred):\\t\\t', set(predictions))\n",
    "print('Unique (correct):\\t', set(correct))\n",
    "\n",
    "# plt.subplot(122)\n",
    "# plt.hist(predictions, bins=11)  # arguments are passed to np.histogram\n",
    "# print(np.histogram(predictions, bins=11))\n",
    "# plt.title('Predictions')\n",
    "\n",
    "# plt.subplot(121)\n",
    "# plt.hist(correct, bins=11)  # arguments are passed to np.histogram\n",
    "# plt.title('Correct')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "429/1040"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
